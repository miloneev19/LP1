ALLLLLLLL



Knapsack 

#include <iostream>
using namespace std;

int main(){
	
	int i,j,k,n,weight,wt;
	
	cout<<"\nEnter the number of elements : ";
	cin>>n;
	cout<<"\nEnter the maximum weight : ";
	cin>>weight;
	
	int p[n],w[n];
	float pw[n],x[n],v[n];
	cout<<"\n=================X Enter data X================\n";
	for(i=0;i<n;i++){
		cout<<"\nWeight : ";
		cin>>w[i];
		cout<<"\nProfit : ";
		cin>>p[i];
		
		pw[i]=(float)p[i]/w[i];
		x[i]=0;
		v[i]=i+1;
		cout<<"\n---------------------------------------------";
	}
	cout<<"\n";
	int bag=0;
	float tp=0,tw=0;
	float mat[n+1][weight+1];
	
	int ch;
	do{
		cout<<"\n\nEnter Your Choice :\n\n \t\t1.Greedy/Fractional\t\t2.Dynamic/0-1\n\n\t\t-->\t";
		cin>>ch;
		switch(ch){
			case 1:{
				
				for(i=0;i<n;i++){
					for(j=i+1;j<n;j++){
						if(pw[i]<pw[j]){
							float temp;
							int t;
							temp=pw[i];
							pw[i]=pw[j];
							pw[j]=temp;
							
							temp=v[i];
							v[i]=v[j];
							v[j]=temp;
							
							t=p[i];
							p[i]=p[j];
							p[j]=t;
							
							t=w[i];
							w[i]=w[j];
							w[j]=t;
							
						}
					}
				}//sorting done
				i=0;
				while(bag<weight){
					if(bag+w[i]<weight){
						x[i]=1;
						bag=bag+w[i];
					}
					else{
						x[i]=(float)(weight-bag)/w[i];
						bag=weight;
					}
					i++;	
				
				}


				for(i=0;i<n;i++){
					for(j=i+1;j<n;j++){
						if(v[i]>v[j]){
							float temp;
							int t;
							temp=pw[i];
							pw[i]=pw[j];
							pw[j]=temp;
							
							temp=v[i];
							v[i]=v[j];
							v[j]=temp;
							
							t=p[i];
							p[i]=p[j];
							p[j]=t;
							
							t=w[i];
							w[i]=w[j];
							w[j]=t;
							
							temp=x[i];
							x[i]=x[j];
							x[j]=temp;							
						}
					}
				}//resorting done
				
				cout<<"\nElement : Fraction\n";
				for(i=0;i<n;i++){
					cout<<v[i]<<"  :  "<<x[i]<<"\n";
				}
				for(i=0;i<n;i++){
					tp=tp+p[i]*x[i];
					tw=tw+w[i]*x[i];
				}
				
				cout<<"\nTotal Profit : "<<tp;
				cout<<"\nTotal Weight : "<<tw;
				
				break;
			}
			case 2:{
				
				for(i=0;i<n;i++){
					x[i]=0;
				}
				
				for(i=0;i<n+1;i++){
					for(j=0;j<weight+1;j++){
						mat[i][0]=0;
						mat[0][j]=0;
					}
				}
				
				for(j=1;j<n+1;j++){
					for(k=1;k<weight+1;k++){
						if(k<w[j-1]){
							mat[j][k]=mat[j-1][k];
						}
						else if(k>=w[j-1]){
							mat[j][k]=max(mat[j-1][k],p[j-1]+mat[j-1][k-w[j-1]]);
						}
					}
				}
				
				
				
				for(i=0;i<n+1;i++){
				    cout<<"\n";
					for(j=0;j<weight+1;j++){
						cout<<mat[i][j]<<"\t";
					}
					cout<<"\n";
				}
				
				i=n;
				wt=weight;
				while(i>0 && wt>0){
					if(mat[i][wt]!=mat[i-1][wt]){
						i--;
						x[i]=1;
						wt=wt-w[i];
					}
					else{
						i--;
					}
				}
				
				cout<<"\n-------------------------------------------------------------------";
				cout<<"\nProfit : ";
				for(i=0;i<n;i++){
					cout<<p[i]<<"\t";
				}
				cout<<"\nWeight : ";
				for(i=0;i<n;i++){
					cout<<w[i]<<"\t";
				}
				cout<<"\nX[]    : ";
				for(i=0;i<n;i++){
					cout<<x[i]<<"\t";
				}
				
				cout<<"\nMaximum profit is : "<<mat[n][weight];
				
				
				break;
			}
			case 3:{
				cout<<"\n\t\tProgram exit!";
				exit(0);
				break;
			}
			default:{
				cout<<"\n\t\tWrong option !";
				break;
			}
		}//end of switch
		
		cout<<"\n-------------------------------------------------------------------";

	}while(ch!=3);
	
	return 0;
}

Bellman 

#include <iostream>
using namespace std;

int main(){
	
	int i,j,u,v,w,n,e,src,p=0,m;
	cout<<"\nEnter the number of vertices : ";
	cin>>n;
	cout<<"\nEnter the source : ";
	cin>>src;
	cout<<"\nEnter the number of edges : ";
	cin>>e;
	
	int mat[n][n],edge[2*e],cost[n],prev[n];
	for(i=0;i<n;i++){
		for(j=0;j<n;j++){
			mat[i][j]=0;
		}
	}
	
	cout<<"\n-------------- Enter edges -------------------";
	for(i=0;i<e;i++){
		cout<<"\nEnter the source : ";
		cin>>u;
		cout<<"\nEnter the destination : ";
		cin>>v;
		cout<<"\nEnter the weight : ";
		cin>>w;
		
		edge[p]=u;
		edge[p+1]=v;
		p=p+2;
		mat[u][v]=w;
	}
	cout<<"\nAdjucency Matrix for Graph is: \n";
	for(i=0;i<n;i++){
		for(j=0;j<n;j++){
			cout<<mat[i][j]<<"\t";
		}
		cout<<"\n";
	}
	p=0;

	cout<<"\nSet of Edges: ";
	for(i=0;i<e;i++){
		cout<<"\t"<<"("<<edge[p]<<","<<edge[p+1]<<")";
		p=p+2;
	}
	
	for(i=0;i<n;i++){
		cost[i]=999;
	}
	cost[src]=0;
	
	
	for(i=0;i<n;i++){
		
		p=0;
		for(j=0;j<e;j++){
			u=edge[p];
			v=edge[p+1];
			p=p+2;
			
			if(cost[u]+mat[u][v]<cost[v])
			{
				cost[v]=cost[u]+mat[u][v];
			}
		}
		
		cout<<"\n Iter "<<i+1<<": ";
		for(m=0;m<n;m++){
			cout<<cost[m]<<"\t";
		}
		
		
		if(i==0){
			for(m=0;m<n;m++){
				prev[m]=cost[m];
			}
		}
		else{
			
			int flag=0;
			for(m=0;m<n;m++){
				if(cost[m]!=prev[m]){
					flag=1;
					break;
				}
			}
		
			if(flag==0){
				cout<<"\n\nAs there is no change in distance matrix, we can stop here .";
				break;
			}
			else if(i==n-1){
				cout<<"\n\nThere is dissimilarity even after n-1 cycles, hence, negative edge cycle present !";
			}
			else{
				for(m=0;m<n;m++){
					prev[m]=cost[m];
				}
			}
			
			
		}//end of else
		
	}//end of for i
	
	return 0;
	
}


N queen 

#include <stdio.h>
#include <math.h>
#include <conio.h>

int count=0,a[30];
int place(int pos)
{
    int i;
    for(i=1;i<pos;i++)
    {
        if((a[i]==a[pos]) || ((abs(a[i]-a[pos])==abs(i-pos))) )       //checking for same column and diagonal
            return 0;
    }
    return 1;
}

void print_sol(int n)
{
    int i,j;
    count++;
    printf("\n\nSolution #%d:\n",count);
    for(i=1;i<=n;i++)
    {
        for(j=1;j<=n;j++)
        {
            if(a[i]==j)
            {
                printf("Q\t");
            }
            else
            {
                printf("*\t");
            }
        }
        printf("\n");
    }
}

void queen(int n)
{
    int k=1;                //nth number of queen.
    a[k]=0;                 //k is the row and a[k] is column.

    while(k!=0)
    {
        do
        {
            a[k]++;
        }while((a[k]<=n)&&!place(k));
        if(a[k]<=n)
        {
            if(k==n)
                print_sol(n);

            else
            {
                k++;
                a[k]=0;
            }
        }
        else
            k--;
    }
}
void main()
{

    int n;
    printf("Enter the number of queens to be placed: ");
    scanf("%d",&n);
    queen(n);
    printf("Total solution are: %d",count);

}


ALL

Linear Regression 

#importing necessary libraries
import numpy as np               
import pandas as pd              
import seaborn as sns      
import matplotlib.pyplot as plt
df=pd.read_csv("/content/temperatures.csv")
df.describe()   
df.info()   
df.isnull()  
df.head() 
df.shape 
x=df["YEAR"]
y=df["ANNUAL"]
plt.plot(x,y)
sns.scatterplot(x=x,y=y,data=df) 
x.shape  
type(x) 
x= x.values     
x=x.reshape(117,1)
type(x)
x.shape 
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression 
x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.25)
model = LinearRegression() 
model.fit(x_train,y_train)
y_pred=model.predict(x_test)
model.coef_
model.intercept_
plt.scatter(x_train,y_train,color="red")
plt.plot(x_test,y_pred,color="black",linewidth="3")
plt.title("Year vs Temp")
plt.xlabel("Year")
plt.ylabel("Temp")
plt.show()
sns.regplot(data=df,x=x_train,y=y_train)
from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score
print(f"MSE : {mean_squared_error(y_test,y_pred)}" )

Classification 

import numpy as np
import pandas as pd 
df=pd.red_csv("/content/Admission_Predict_Ver1.1.csv")
df.columns
from sklearn.preprocessing imoort Binarizer 
bi=Binarizer(threshold=0.75)
df['Chance of Admit ']=bi.fit_transform(df[['Chance of Admit ']])
df
x=df.drop('Chance of Admit ',axis=1)
y=df['Chance of Admit ']
y=y.astype('int')
y
y.value_counts()
from sklearn.model_selection import train_test_split 
x_train,x_test,y_train,y_test=train_test_split(x,y)
from sklearn.tree import DecisionTreeClassifier 
classifier=DecisionTreeClassifier(random_state=0)
classfier.fit(x_train,y_train)
from sklearn import tree 
import matplotlib.pyplot as plt 
plt.figure(figsize=(30,30))
tree.plot_tree(classifier,filled=True, fontsize=16)
plt.show()
from sklearn.metrices import classification_report 
y_pred=classifier.predict(x_test)
print(classification_report(y_test,y_pred))
from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test,y_pred)

Classifier Model 

import numpy as np
import pandas as pd
df=pd.read_csv('/content/spam.csv',encoding='ISO-8859-1')
df.head()
df.info()
df.groupby('v1').describe()
df['spam'] = df['v1'].apply(lambda x:1 if x=='spam' else 0)
df.head()
new_df = df[['v1','v2','spam']]
new_df.head()
from sklearn.model_selection import train_test_split as tts
x_train,x_test,y_train,y_test=tts(df.v2,df.spam)
from sklearn.feature_extraction.text import CountVectorizer
v=CountVectorizer()
x_train_count=v.fit_transform(x_train.values)
x_train_count.toarray()[:2]
from sklearn.naive_bayes import MultinomialNB
model=MultinomialNB()
model.fit(x_train_count,y_train)
emails=["How are you brother?", "Free entry"]
email_count=v.transform(emails)
model.predict(email_count)
x_test_count=v.transform(x_test)
model.score(x_test_count,y_test)

Clustering 

from sklearn.cluster import KMeans
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from matplotlib import pyplot as plt
%matplotlib inline
df = pd.read_csv("/content/income.csv")
df.head()
plt.scatter(df.Age,df['Income'])
plt.xlabel('Age')
plt.ylabel('Income')
km = KMeans(n_clusters=3)
y_predicted = km.fit_predict(df[['Age','Income']])
y_predicted
df['cluster']=y_predicted
df.head()
km.cluster_centers_
df1 = df[df.cluster==0]
df2 = df[df.cluster==1]
df3 = df[df.cluster==2]
plt.scatter(df1.Age,df1['Income'],color='green')
plt.scatter(df2.Age,df2['Income'],color='red')
plt.scatter(df3.Age,df3['Income'],color='black')
plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color='purple',marker='*',la
plt.xlabel('Age')
plt.ylabel('Income')
plt.legend()
scaler = MinMaxScaler()
scaler.fit(df[['Income']])
df['Income'] = scaler.transform(df[['Income']])
scaler.fit(df[['Age']])
df['Age'] = scaler.transform(df[['Age']])
plt.scatter(df.Age,df['Income'])
km = KMeans(n_clusters=3)
y_predicted = km.fit_predict(df[['Age','Income']])
y_predicted
df['cluster']=y_predicted
df.head()
km.cluster_centers_
df1 = df[df.cluster==0]
df2 = df[df.cluster==1]
df3 = df[df.cluster==2]
plt.scatter(df1.Age,df1['Income'],color='green')
plt.scatter(df2.Age,df2['Income'],color='red')
plt.scatter(df3.Age,df3['Income'],color='black')
plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color='purple',marker='*',la
plt.legend()
sse = []
k_rng = range(1,10)
for k in k_rng:
km = KMeans(n_clusters=k)
km.fit(df[['Age','Income']])
sse.append(km.inertia_) # inertia will calculate SSE
plt.xlabel('K')
plt.ylabel('Sum of squared error')
plt.plot(k_rng,sse)


Association Rule

!pip install mlxtend
import csv
import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend. frequent_patterns import apriori, association_rules
dataset = []
with open("/content/merket.csv") as file:
reader = csv.reader(file, delimiter=",")
for row in reader:
dataset.append(row)
dataset
te = TransactionEncoder()
df=te.fit_transform(dataset)
df = pd.DataFrame(df, columns= te.columns_)
df
item_set = apriori(df, min_support=0.01, use_colnames=True)
item_set
rules= association_rules(item_set, metric="confidence", min_threshold=0.25)
print (f" Confidence Level: 25%, No of rules: {len(rules)}")
rules
rules= association_rules(item_set, metric="confidence", min_threshold=0.20)
print (f" Confidence Level: 20%, No of rules: {len(rules)}")
rules
rules = rules [["antecedents", "consequents", "support", "confidence"]]
rules
#Recommendation
ip = "milk"
ip = input("Enter the item to purchase : ")
rules[rules["antecedents"] == {ip}]["consequents"]

